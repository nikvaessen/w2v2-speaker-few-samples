# probability of regularization techniques during training
# dropout
activation_dropout: 0.0  # in feed-forward module of transformer layer
attention_dropout: 0.0  # in attention module of transformer layer
feat_proj_dropout: 0.0  # in feature projection module
hidden_dropout: 0.0  # between residual connections in transformer layer
final_dropout: 0.00  # on input to final classification layer

# layer skip in transformer
layerdrop: 0.0

# specaugment
# feature
mask_feature_length: 10
mask_feature_prob: 0.0

# time
mask_time_length: 10
mask_time_prob: 0.00